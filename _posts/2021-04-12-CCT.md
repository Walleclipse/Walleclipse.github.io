---
layout: post
title:  "Escaping the big data paradigm with compact transformers"
date:   2021-04-12 18:08:39 +00:00
image: /images/CCT.png
categories: research
author: "Abulikemu Abuduweili"
authors: "Ali Hassani, Steven Walton, Nikhil Shah, <strong>Abulikemu Abuduweili</strong>,  Jiachen Li, Humphrey Shi"
venue: "CVPR workshop on Learning from Limited and Imperfect Data, [Invited Talk]"
arxiv: https://arxiv.org/abs/2104.05704 
code: https://github.com/SHI-Labs/Compact-Transformers 
youtube: https://www.youtube.com/watch?v=AEWhf_hMBgs 
---


In this paper, we dispel the myth that transformers are “data hungry” and therefore can only be applied to large sets of data. 
We show for the first time that with the right size and tokenization, transformers can perform head-to-head with state-of-the-art CNNs on small datasets, 
often with better accuracy and fewer parameters.
