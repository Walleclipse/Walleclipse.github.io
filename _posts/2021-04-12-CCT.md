---
layout: post
title:  "Escaping the Big Data Paradigm with Compact Transformers"
date:   2021-04-12 18:08:39 +00:00
image: /images/CCT.png
categories: research
author: "Abulikemu Abuduweili"
authors: "Ali Hassani, Steven Walton, Nikhil Shah, <strong>Abulikemu Abuduweili</strong>,  Jiachen Li, Humphrey Shi"
venue: "CVPR Workshop on Learning from Limited and Imperfect Data  <strong>[Invited Talk]</strong>"
arxiv: https://arxiv.org/abs/2104.05704 
code: https://github.com/SHI-Labs/Compact-Transformers 
video: https://www.youtube.com/watch?v=AEWhf_hMBgs 
blog: https://medium.com/pytorch/training-compact-transformers-from-scratch-in-30-minutes-with-pytorch-ff5c21668ed5
highlight: true
---

Everyone assumed Vision Transformers need massive datasetsâ€”we proved them wrong. By rethinking model size and tokenization, our Compact Convolutional Transformer (CCT) achieves 98% accuracy on CIFAR-10 using just 3.7M parameters. That's better than other transformers and rivals ResNet at a fraction of the size. The takeaway: with the right architecture choices, transformers can thrive on small data too.