---
layout: post
title:  "KOROL: Learning Visualizable Object Feature with Koopman Operator Rollout for Manipulation"
date:   2024-11-08 18:08:39 +00:00
image: /images/KOROL.gif
categories: research
author: "Abulikemu Abuduweili"
authors: "Hongyi Chen, <strong>Abulikemu Abuduweili</strong>,  Aviral Agrawal, Yunhai Han, Harish Ravichandar, Changliu Liu, Jeffrey Ichnowski"
venue: "Conference on Robot Learning (CoRL)"
location: "Munich, Germany"
arxiv: https://openreview.net/forum?id=A6ikGJRaKL 
code: https://github.com/hychen-naza/KOROL 
video: https://x.com/i/status/1832866560270385233 
---

How can a robot manipulate objects it's never seen before, using only camera images? KOROL (Koopman Operator Rollout) learns to extract object features from images and propagate them forward in time using Koopman theoryâ€”no need for ground-truth object poses. The learned features are inherently visualizable, so we can actually see what the robot "understands." In real-world manipulation experiments, KOROL achieves high success rates even on novel objects.