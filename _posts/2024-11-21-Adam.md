---
layout: post
title:  "Revisiting the Initial Steps in Adaptive Gradient Descent Optimization"
date:   2024-11-21 18:08:39 +00:00
image: /images/AdamInit.png
categories: research
author: "Abulikemu Abuduweili"
authors: "<strong>Abulikemu Abuduweili</strong>, Changliu Liu"
venue: " Annual Workshop on Optimization for Machine Learning (OPT)"
location: "Vancouver, Canada"
arxiv: https://arxiv.org/abs/2412.02153 
code: https://github.com/Walleclipse/Adam_Initialization/ 
---



This work identifies the standard initialization of Adam's second-order moment estimation as a key factor limiting generalization. It proposes effective solutions, including non-zero initialization with data-driven or random strategies, to improve performance.